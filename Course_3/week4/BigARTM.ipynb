{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример использования библиотеки BigARTM для тематического моделирования\n",
    "## Для Bigartm v0.8.0\n",
    "### Редактировал Максим Чурилин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем BigARTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import artm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое считывание данных (преобразуем удобный для человека формат в формат, который использует модель):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DiskReadException",
     "evalue": "File school.txt does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDiskReadException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ea9f4ca5f9a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_vectorizer = artm.BatchVectorizer(data_path=\"school.txt\", data_format=\"vowpal_wabbit\", target_folder=\"school_batches\", \n\u001b[1;32m----> 2\u001b[1;33m                                        batch_size=100)\n\u001b[0m",
      "\u001b[1;32mC:\\BigARTM\\Python\\artm\\batches_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batches, collection_name, data_path, data_format, target_folder, batch_size, batch_name_type, data_weight, n_wd, vocabulary, gather_dictionary, class_ids, process_in_memory_model)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'vowpal_wabbit'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uci_or_vw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'vw'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bow_uci'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             self._parse_uci_or_vw(data_weight=data_weight,\n",
      "\u001b[1;32mC:\\BigARTM\\Python\\artm\\batches_utils.py\u001b[0m in \u001b[0;36m_parse_uci_or_vw\u001b[1;34m(self, data_weight, format, col_name, batch_name_type, class_ids)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLibArtm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArtmParseCollection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m             \u001b[0mbatch_filenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.batch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batches_list\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_filenames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\BigARTM\\Python\\artm\\wrapper\\api.py\u001b[0m in \u001b[0;36martm_api_call\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mc_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;31m# return result value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\BigARTM\\Python\\artm\\wrapper\\api.py\u001b[0m in \u001b[0;36m_check_error\u001b[1;34m(self, error_code)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mexception_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mARTM_EXCEPTION_BY_CODE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexception_class\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDiskReadException\u001b[0m: File school.txt does not exist."
     ]
    }
   ],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path=\"school.txt\", data_format=\"vowpal_wabbit\", target_folder=\"school_batches\", \n",
    "                                       batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующий раз данные можно считывать уже из батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path=\"school_batches\", data_format='batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем объект модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10   # количество тем\n",
    "model_artm = artm.ARTM(num_topics=T, topic_names=[\"sbj\"+str(i) for i in range(T)], class_ids={\"text\":1}, \n",
    "                       num_document_passes=1, reuse_theta=True, cache_theta=True, seed=-1)\n",
    "# число после названия модальностей - это их веса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь и инициализируем модель с его помощью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = artm.Dictionary('dictionary')\n",
    "dictionary.gather(batch_vectorizer.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.scores.add(artm.PerplexityScore(name='PerplexityScore',\n",
    "                                           use_unigram_document_model=False,\n",
    "                                           dictionary='dictionary'))\n",
    "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore', class_id=\"text\"))\n",
    "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_artm.scores.add(artm.TopTokensScore(name=\"top_words\", num_tokens=15, class_id=\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.initialize('dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим модель. Offline - проходит по всей коллекции много раз. Удобно, когда коллекция маленькая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимое число итераций можно отслеживать по графику перплексии. Когда она перестала меняться, модель сошлась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_artm.score_tracker[\"PerplexityScore\"].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем топы слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_name in model_artm.topic_names:\n",
    "    print topic_name + ': ',\n",
    "    tokens = model_artm.score_tracker[\"top_words\"].last_tokens\n",
    "    for word in tokens[topic_name]:    \n",
    "        print word,\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим также на разреженность матриц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model_artm.score_tracker[\"SparsityPhiScore\"].last_value\n",
    "print model_artm.score_tracker[\"SparsityThetaScore\"].last_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В темах много общеупотребительных слов (так называемой, фоновой лексики). Чтобы этого избежать, будем использовать разреживающий регуляризатор для матрицы фи. Он будет подавлять слова, которые имеют большую частоту во всей коллекции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-100, dictionary=dictionary, class_ids=\"text\"))\n",
    "#если вы хотите применять регуляризатор только к некоторым модальностям, указывайте это в параметре class_ids: class_ids=[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_name in model_artm.topic_names:\n",
    "    print topic_name + ': ',\n",
    "    tokens = model_artm.score_tracker[\"top_words\"].last_tokens\n",
    "    for word in tokens[topic_name]:    \n",
    "        print word,\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model_artm.score_tracker[\"SparsityPhiScore\"].last_value\n",
    "print model_artm.score_tracker[\"SparsityThetaScore\"].last_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем менять коэффициент регуляризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.regularizers['SparsePhi'].tau = -5*1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_name in model_artm.topic_names:\n",
    "    print topic_name + ': ',\n",
    "    tokens = model_artm.score_tracker[\"top_words\"].last_tokens\n",
    "    for word in tokens[topic_name]:    \n",
    "        print word,\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# еще раз посмотрим на разреженность\n",
    "print model_artm.score_tracker[\"SparsityPhiScore\"].last_value\n",
    "print model_artm.score_tracker[\"SparsityThetaScore\"].last_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что разреживать модель рекомендуется только после того, как она сошлась без регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение и загрузка модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.load(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно попросить матрицы в чистом виде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = model_artm.get_phi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица вероятностей тем в документах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = model_artm.get_theta()\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если бы у нас были новые батчи, по которым мы не строим модель, а хотим только получить матрицу theta, можно пользоваться методом transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_test = model_artm.transform(batch_vectorizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
